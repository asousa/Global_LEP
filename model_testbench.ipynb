{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austin/miniconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: text.fontsize is deprecated and replaced with font.size; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "#from build_database import flux_obj\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "import random\n",
    "import os\n",
    "%matplotlib inline\n",
    "# Autoload changes made in external editor:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --------------- Latex Plot Beautification --------------------------\n",
    "fig_width_pt = 650.0  # Get this from LaTeX using \\showthe\\columnwidth\n",
    "inches_per_pt = 1.0/72.27               # Convert pt to inch\n",
    "golden_mean = (np.sqrt(5)-1.0)/2.0         # Aesthetic ratio\n",
    "fig_width = fig_width_pt*inches_per_pt  # width in inches\n",
    "fig_height = fig_width*golden_mean*2      # height in inches\n",
    "fig_size =  [fig_width+1,fig_height+1]\n",
    "params = {'backend': 'ps',\n",
    "          'axes.labelsize': 14,\n",
    "          'text.fontsize': 14,\n",
    "          'legend.fontsize': 10,\n",
    "          'xtick.labelsize': 10,\n",
    "          'ytick.labelsize': 10,\n",
    "          'text.usetex': False,\n",
    "          'figure.figsize': fig_size}\n",
    "plt.rcParams.update(params)\n",
    "# --------------- Latex Plot Beautification --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from measurement_model import measurement_model\n",
    "from precip_model import precip_model\n",
    "from GLD_file_tools import GLD_file_tools\n",
    "from coordinate_structure import transform_coords\n",
    "import datetime as dt\n",
    "\n",
    "p = precip_model(database=\"database_dicts.pkl\",multiple_bands = False)\n",
    "gld = GLD_file_tools('GLD_mount',prefix='GLD')\n",
    "\n",
    "td = dt.timedelta(seconds = 10)\n",
    "\n",
    "# Output grid space:\n",
    "out_lat_grid = np.arange(-90, 89, step=1)\n",
    "out_lon_grid = np.arange(-180,179,step=1)\n",
    "\n",
    "out_grid = np.meshgrid(out_lat_grid, out_lon_grid)\n",
    "\n",
    "print np.shape(out_grid)\n",
    "\n",
    "T_STEP = p.db[p.db.keys()[0]]['RES_DT']\n",
    "T_MAX  = p.db[p.db.keys()[0]]['RES_FINT']\n",
    "NUM_STEPS = np.round(T_MAX/T_STEP)\n",
    "\n",
    "\n",
    "in_time_str = \"2015-11-01T12:45:00\"\n",
    "in_time = dt.datetime.strptime(in_time_str,  \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "time_sampling_vector = np.linspace(-T_MAX,0,NUM_STEPS)\n",
    "\n",
    "lat_ind = 7\n",
    "lon_ind = 8\n",
    "mag_ind = 9\n",
    "\n",
    "flashes, flash_times = gld.load_flashes(in_time, td)\n",
    "if flashes is None:\n",
    "    print \"No flashes found at \", in_time\n",
    "else:\n",
    "    print np.shape(flashes)\n",
    "\n",
    "flashes = flashes[:,(lat_ind, lon_ind, mag_ind, mag_ind)]\n",
    "flash_coords = transform_coords(flashes[:,0], flashes[:,1], np.zeros_like(flashes[:,0]), 'geographic', 'geomagnetic')\n",
    "flashes[:,:2] = flash_coords[:,:2]\n",
    "flashes[:,3] = [(in_time - s).microseconds*1e-6 + (in_time - s).seconds for s in flash_times]\n",
    "\n",
    "\n",
    "# Mask out flashes outside the range of the interpolator:\n",
    "mask = (  (np.abs(flashes[:,0]) > 10) \n",
    "        & (np.abs(flashes[:,0]) < 60)) \n",
    "        # (flashes[:,2] > 50))\n",
    "\n",
    "# Mask out flashes not of interest to the satellite:\n",
    "# atten_factors = longitude_scaling(flash_coords, sat.coords)\n",
    "# mask = atten_factors < 24\n",
    "\n",
    "print \"%g flashes (post-filter)\" % np.sum(mask)\n",
    "\n",
    "masked_flashes = flashes[mask, :]    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# flux = 0\n",
    "flux = np.zeros(np.shape(out_grid)[1:])\n",
    "# for lati, lat in enumerate(out_lat_grid):\n",
    "#     for loni, lon in enumerate(out_lon_grid):\n",
    "# for f in flashes:\n",
    "    #print td.seconds - f[3]   \n",
    "#     flux += np.sum( p.get_precip_at(f[0], lat, time_sampling_vector + f[3]) *\n",
    "#                       p.get_longitude_scaling(f[0], f[1], lon, I0=f[2]) * T_STEP )\n",
    "\n",
    "in_lat = 40\n",
    "in_lon = 0\n",
    "in_del = 10\n",
    "lat_vec = np.zeros_like(out_lat_grid)\n",
    "\n",
    "for f in masked_flashes:\n",
    "    # Get interpolated lat grid \n",
    "    for lati, lat in enumerate(out_lat_grid):\n",
    "        lat_vec[lati] = np.sum(p.get_precip_at(f[0], lat, time_sampling_vector + f[3]))\n",
    "\n",
    "    lon_vec = p.get_longitude_scaling(f[0],f[1], out_lon_grid, I0 = f[2])\n",
    "    flux += np.outer(lon_vec, lat_vec)\n",
    "\n",
    "    \n",
    "print \"max flux:\", np.max(flux)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# T_STEP = p.db[p.db.keys()[0]]['RES_DT']\n",
    "# T_MAX  = p.db[p.db.keys()[0]]['RES_FINT']\n",
    "# print RES_DT\n",
    "# print T_MAX\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.log10(flux.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt=30\n",
    "\n",
    "tmask = (masked_flashes[:,3] + grid_time[tt] > 0 ) & (masked_flashes[:,3] + grid_time[tt] < 1)\n",
    "print masked_flashes[tmask,3]\n",
    "plt.pcolor(grid_lons, grid_lats, np.log10(N_grid[:,:,tt].T))\n",
    "plt.clim([-12,0])\n",
    "plt.pcolor(grid_lons, -1*np.flipud(grid_lats), np.fliplr(np.log10(S_grid[:,:,tt])).T)\n",
    "plt.clim([-12,0])\n",
    "plt.colorbar()\n",
    "plt.scatter(masked_flashes[tmask,1], masked_flashes[tmask,0],marker='.')\n",
    "plt.scatter(sat.coords.lon(), sat.coords.lat(),marker='x',color='red')\n",
    "#plt.scatter(masked_coords.lon(), masked_coords.lat())\n",
    "#plt.clim([-12,0])\n",
    "plt.show() \n",
    "\n",
    "# for tt in grid_time:\n",
    "#     plt.pcolor(grid_lons, grid_lats, np.log10(N_grid[:,:,tt].T))\n",
    "#     plt.clim([-8,4])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "succeeded:  sc.PI = 3.14159265358979311599796346854418516159\n",
      "failed: sc.D2R = PI/180.0\n",
      "failed: sc.R2D = 180.0/PI\n",
      "succeeded:  sc.Q_EL = 1.602E-19\n",
      "succeeded:  sc.M_EL = 9.1E-31\n",
      "succeeded:  sc.E_EL = 5.105396765648739E5\n",
      "failed: sc.MU0 = PI*4E-7\n",
      "succeeded:  sc.EPS0 = 8.854E-12\n",
      "succeeded:  sc.C = 2.997956376932163e+08\n",
      "succeeded:  sc.Z0 = 377.0\n",
      "succeeded:  sc.R_E = 6370000.0\n",
      "succeeded:  sc.H_MAGNETO = 1E6\n",
      "succeeded:  sc.H_IONO = 1E5\n",
      "succeeded:  sc.A = 5E3\n",
      "succeeded:  sc.B = 1E5\n",
      "succeeded:  sc.H_E = 5000.0\n",
      "succeeded:  sc.P_DIST = 0.0\n",
      "succeeded:  sc.Q_DIST = 2.0\n",
      "succeeded:  sc.AN_CM_DIST = 2E5\n",
      "succeeded:  sc.V0_DIST = 1.0\n",
      "succeeded:  sc.M_RES = 0\n",
      "succeeded:  sc.E_MIN = 10E3\n",
      "succeeded:  sc.E_MAX = 5E6\n",
      "succeeded:  sc.NUM_E = 8\n",
      "succeeded:  sc.SQUARE = 1\n",
      "failed: sc.E_EXP_BOT = log10(E_MIN)\n",
      "failed: sc.E_EXP_TOP = log10(E_MAX)\n",
      "failed: sc.DE_EXP = ((E_EXP_TOP\n",
      "succeeded:  sc.EALimS = -40.0\n",
      "succeeded:  sc.EALimN = 40.0\n",
      "succeeded:  sc.EAIncr = 1.0\n",
      "succeeded:  sc.dL0 = 6E-4\n",
      "succeeded:  sc.DF = 50.0\n",
      "succeeded:  sc.DT = 0.01\n",
      "failed: sc.NUMLATS = ((EALimN\n",
      "succeeded:  sc.EA_SPLIT = 1\n",
      "succeeded:  sc.MULT = 2.0\n",
      "succeeded:  sc.WAVE_PWR_THRESH = 1e-6\n",
      "succeeded:  sc.RAYTRACE_TIME = 45\n",
      "succeeded:  sc.T_STEP = 0.0004\n",
      "succeeded:  sc.NUM_STEPS = 112500\n",
      "succeeded:  sc.RES_DT = 0.05\n",
      "succeeded:  sc.RES_FINT = 45\n",
      "succeeded:  sc.LK = 5.39\n",
      "succeeded:  sc.I0 = -100000.000000\n",
      "in lats: [10 15 20 25 30 35 40 45 50 55 60 65]\n",
      "sc T_STEP: 0.05\n",
      "N NaNs: 0\n",
      "S NaNs: 0\n",
      "N NaNs: 0\n",
      "S NaNs: 0\n",
      "N NaNs: 0\n",
      "S NaNs: 0\n",
      "N NaNs: 0\n",
      "S NaNs: 0\n",
      "N NaNs: 0\n",
      "S NaNs: 0\n",
      "N NaNs: 0\n",
      "S NaNs: 0\n",
      "N NaNs: 0\n",
      "S NaNs: 0\n",
      "N NaNs: 0\n",
      "S NaNs: 0\n",
      "N NaNs: 0\n",
      "S NaNs: 0\n",
      "N NaNs: 0\n",
      "S NaNs: 0\n",
      "N NaNs: 0\n",
      "S NaNs: 0\n",
      "N NaNs: 0\n",
      "S NaNs: 0\n",
      "Saving database\n"
     ]
    }
   ],
   "source": [
    "from build_database import build_database\n",
    "from load_sim_constants import load_sim_constants\n",
    "from load_phi_files import load_phi_files\n",
    "\n",
    "old_dir = '/Users/austin/FUSE/shared/users/asousa/WIPP/WIPPv3/outputs/probably/run_sat/'\n",
    "\n",
    "# sc = load_sim_constants(os.path.join(old_dir,'codesrc/consts.h'),old_format=True)\n",
    "\n",
    "# N, S, L = load_phi_files(old_dir + \"in_45\", sc)\n",
    "\n",
    "# print \"max N:\", np.max(N)\n",
    "# print \"min N:\", np.min(N)\n",
    "\n",
    "# print np.shape(N)\n",
    "\n",
    "build_database(input_dir = old_dir, output_filename = \"db_test2.pkl\",old_format = True, t_new_step=0.5, num_L = 33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 15 20 25 30 35 40 45 50 55 60 65]\n",
      "['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__']\n",
      "['__class__', '__cmp__', '__contains__', '__delattr__', '__delitem__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'has_key', 'items', 'iteritems', 'iterkeys', 'itervalues', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values', 'viewitems', 'viewkeys', 'viewvalues']\n",
      "/Users/austin/FUSE/shared/users/asousa/WIPP/global_precip\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"db_test2.pkl\",'r') as file:\n",
    "    deebee = pickle.load(file)\n",
    "file.close()    \n",
    "print deebee['in_lats']\n",
    "print dir(deebee['consts'])\n",
    "print dir(deebee)\n",
    "\n",
    "print os.getcwd()\n",
    "# clims = [-3,2]\n",
    "# for il_ind, il_val in enumerate(db['in_lats']):\n",
    "#     data = db['N_el'][il_ind,:,:]\n",
    "#     print \"N ranges: \",np.min(data), np.max(data)\n",
    "#     plt.figure()\n",
    "    \n",
    "#     Nv = np.log10(data)\n",
    "#     Nv = np.clip(Nv,clims[0],clims[1])\n",
    "#     plt.imshow(Nv,origin='lower',interpolation='none')\n",
    "#     plt.clim(clims)\n",
    "#     plt.ylabel(il_val)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"db_test.pkl\",'rb') as file:\n",
    "    db = pickle.load(file)\n",
    "\n",
    "print db.keys()\n",
    "sc = db['consts']\n",
    "print dir(sc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's downsample the things!\n",
    "\n",
    "\n",
    "new_step = 0.5  # seconds\n",
    "t = db[in_lats[0]]['t']\n",
    "\n",
    "\n",
    "t_new = np.arange(0,T_MAX, step=new_step) # New time vector\n",
    "intervals = np.round(t_new*NUM_STEPS/T_MAX).astype(int) # Intervals to sum between\n",
    "\n",
    "# print t[intervals]\n",
    "# t = db[in_lats[0]]['t']\n",
    "\n",
    "\n",
    "in_tmp = N_arr[3,:,:]\n",
    "out_tmp= np.zeros([len(in_lats),len(L_vec), len(t_new)])\n",
    "\n",
    "for ind, Tp in enumerate(zip(intervals[0:], intervals[1:])):\n",
    "    print ind, Tp\n",
    "    out_tmp[3,:,ind] = np.sum(N_arr[3,:,Tp[0]:Tp[1]],axis=1)\n",
    "\n",
    "plt.imshow(np.log10(out_tmp[3,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot typical data from the precipitation model:\n",
    "# time x out_lat,   1 plot per in_lat\n",
    "\n",
    "from precip_model import precip_model\n",
    "\n",
    "p = precip_model(database=\"db_test.pkl\", cumsum=False)\n",
    "\n",
    "lat_targ = np.arange(-80,80,step=0.1)\n",
    "in_lat_targ = np.arange(5,70,step=7.5)\n",
    "num_inlats = len(in_lat_targ)\n",
    "t = p.t\n",
    "\n",
    "clims = [-3,4]\n",
    "\n",
    "interp_d = p.get_multiple_precip_at(in_lat_targ, lat_targ, t)\n",
    "print np.shape(interp_d)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = []\n",
    "for i,lat in enumerate(in_lat_targ):\n",
    "    ax.append(fig.add_subplot(1,num_inlats,i+1))\n",
    "    #Nv = np.log10(interp_d[i,:,2:] - interp_d[i,:,0:-2])\n",
    "    Nv = np.log10(interp_d[i,:,:])\n",
    "\n",
    "\n",
    "    Nv = np.clip(Nv,clims[0],clims[1])\n",
    "    pl = plt.imshow(Nv,origin='lower',interpolation='none')\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "    ax[i].set_xlabel(lat)\n",
    "    plt.clim(clims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'constants_struct'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e75d2857cdac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test scaling factor:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprecip_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecip_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecip_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"db_test.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minp_lat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/austin/FUSE/shared/users/asousa/WIPP/global_precip/precip_model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, database, multiple_bands, cumsum)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# in_lats = sorted(self.db.keys())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/austin/miniconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/austin/miniconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/austin/miniconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/austin/miniconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'constants_struct'"
     ]
    }
   ],
   "source": [
    "# Test scaling factor:\n",
    "from precip_model import precip_model\n",
    "p = precip_model(database=\"db_test.pkl\")\n",
    "\n",
    "inp_lat = 45\n",
    "inp_lon = 0\n",
    "out_lat = np.arange(-90,90)\n",
    "out_lon = np.arange(-180,180)\n",
    "\n",
    "# D2R = np.pi/180.0\n",
    "# R_E = 6378.0\n",
    "# dlat  = D2R*(out_lat - inp_lat)\n",
    "# dlong = D2R*(out_lon - inp_lon)\n",
    "# clat1 = np.cos(D2R*inp_lat)\n",
    "# clat2 = np.cos(D2R*out_lat)\n",
    "# slat1 = np.sin(D2R*inp_lat)\n",
    "# slat2 = np.sin(D2R*out_lat)\n",
    "\n",
    "# # Vincenty solution (spherical)\n",
    "# # a = np.outer(clat2, np.sin(dlong))\n",
    "# # b = clat1*slat2[:,np.newaxis] - np.outer(slat1*clat2, np.cos(dlong))\n",
    "# # c = slat1*slat2[:,np.newaxis] + np.outer(clat1*clat2, np.cos(dlong))\n",
    "\n",
    "# # D = 6378*np.arctan2( np.sqrt(pow(a,2) + pow(b,2)), c)\n",
    "\n",
    "# # Haversine formula:\n",
    "# a = pow(np.sin(dlat/2.0),2)\n",
    "# b = (clat1*np.outer(clat2, pow(np.sin(dlong/2.0),2)))\n",
    "\n",
    "# D = 2.0*R_E * np.arcsin(np.sqrt(a[:,np.newaxis] + b))\n",
    "\n",
    "ratio, new_weight, old_weight = p.get_longitude_scaling(inp_lat, inp_lon, out_lat, out_lon, I0=-10000)\n",
    "\n",
    "print np.max(ratio)\n",
    "print np.min(ratio)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(311)\n",
    "p1 = ax1.imshow(np.log10(ratio),origin='lower')\n",
    "plt.colorbar(p1)\n",
    "\n",
    "ax2 = fig.add_subplot(312)\n",
    "p2 = ax2.imshow(np.log10(new_weight),origin='lower')\n",
    "plt.colorbar(p2)\n",
    "ax3 = fig.add_subplot(313)\n",
    "\n",
    "p3 = ax3.plot(old_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load flashes, calculate total precipitation (el/(cm^2)) within a time window:\n",
    "import numpy as np\n",
    "from GLD_file_tools import GLD_file_tools\n",
    "from precip_model import precip_model\n",
    "from calc_global_precip import calc_global_precip\n",
    "\n",
    "\n",
    "# Instantiate objects:\n",
    "p = precip_model(database=\"db_test.pkl\", cumsum=True)\n",
    "gld = GLD_file_tools('GLD_mount',prefix='GLD')\n",
    "\n",
    "in_lat_grid  = np.arange(-70,70, step=0.1)\n",
    "out_lat_grid = np.arange(-90,90,step=0.5)\n",
    "out_lon_grid = np.arange(-180,180,step=0.5)\n",
    "# out_grid = np.meshgrid(out_lat_grid, out_lon_grid)\n",
    "\n",
    "# precip_map = np.zeros_like(out_grid)\n",
    "\n",
    "in_time_str = \"2015-11-01T10:45:00\"\n",
    "in_time = dt.datetime.strptime(in_time_str,  \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# flux = calc_global_precip(p, gld, in_time, 1, out_lat_grid, out_lon_grid)\n",
    "print np.shape(in_lat_grid)\n",
    "print np.shape(out_lat_grid)\n",
    "print np.shape(p.t)\n",
    "\n",
    "p.precalculate_gridded_values(in_lat_grid, out_lat_grid, p.t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat_ind = 7\n",
    "lon_ind = 8\n",
    "mag_ind = 9\n",
    "# How far back to load flashes from:\n",
    "td = dt.timedelta(seconds=30)\n",
    "\n",
    "print \"Loading flashes...\"\n",
    "\n",
    "flashes, flash_times = gld.load_flashes(in_time, td)\n",
    "\n",
    "# print flash_times\n",
    "if flashes is None:\n",
    "    print \"No flashes found at \", in_time\n",
    "else:\n",
    "    print np.shape(flashes)\n",
    "\n",
    "flashes = flashes[:,(lat_ind, lon_ind, mag_ind, mag_ind)]\n",
    "flash_coords = transform_coords(flashes[:,0], flashes[:,1], np.zeros_like(flashes[:,0]), 'geographic', 'geomagnetic')\n",
    "flashes[:,:2] = flash_coords[:,:2]\n",
    "flashes[:,3] = [(in_time - s).microseconds*1e-6 + (in_time - s).seconds for s in flash_times]\n",
    "\n",
    "\n",
    "# Mask out flashes outside the range of the interpolator:\n",
    "mask = (  (np.abs(flashes[:,0]) > 10) \n",
    "        & (np.abs(flashes[:,0]) < 60)) \n",
    "\n",
    "print \"%g flashes (post-filter)\" % np.sum(mask)\n",
    "\n",
    "masked_flashes = flashes[mask, :]\n",
    "\n",
    "\n",
    "print \"Getting grid indexes\"\n",
    "\n",
    "def nearest_index(grid, values):\n",
    "    # Find closest index of a value in an array (i.e., quick quantize to grid value)\n",
    "    idx = np.searchsorted(grid, values, side=\"left\")\n",
    "    idx = np.clip(idx, 0, len(grid) - 1)\n",
    "    idx_l = np.clip(idx - 1, 0, len(grid) - 1)\n",
    "    idx[abs(values - grid[idx_l]) < abs(values - grid[idx])] -= 1\n",
    "    return idx\n",
    "\n",
    "\n",
    "in_lat_inds  = nearest_index(p.pc_in_lats,  masked_flashes[:,0])\n",
    "t_end_inds   = nearest_index(p.pc_t,masked_flashes[:,3])\n",
    "t_start_inds = nearest_index(p.pc_t, masked_flashes[:,3] - 1.0)\n",
    "\n",
    "# (num_flashes x num_outlats)\n",
    "lv = (p.precalculated[in_lat_inds, : , t_end_inds] - p.precalculated[in_lat_inds, : , t_start_inds])\n",
    "\n",
    "flux = np.zeros([len(out_lat_grid), len(out_lon_grid)])\n",
    "\n",
    "for ind, f in enumerate(masked_flashes):\n",
    "    scalefactor, _, _ = p.get_longitude_scaling(f[0], f[1], out_lat_grid, out_lon_grid, I0 = f[2])\n",
    "    lv_single = lv[ind,:].squeeze()\n",
    "    scalefactor*lv_single[:,np.newaxis]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"flux ranges: \",np.min(flux),np.max(flux)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "# p1 = ax1.imshow(flux,origin='lower')\n",
    "p1 = ax1.pcolor(out_lon_grid, out_lat_grid, flux)\n",
    "# p1.set_clim([-10,-4])\n",
    "plt.colorbar(p1)\n",
    "p2 = ax1.scatter(masked_flashes[:,1],masked_flashes[:,0],marker='x',color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"\n",
    "    Generate a cartesian product of input arrays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "\n",
    "    m = n / arrays[0].size\n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m,1:])\n",
    "        for j in xrange(1, arrays[0].size):\n",
    "            out[j*m:(j+1)*m,1:] = out[0:m,1:]\n",
    "    return out\n",
    "\n",
    "\n",
    "tmp = cartesian([[1,2,3],[4,5,6],[7,8,9,10]])\n",
    "print tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
